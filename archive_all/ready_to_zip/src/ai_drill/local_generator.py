# ë¡œì»¬(LLM ì—†ëŠ”) ë³€í™˜ìš© ë‹¨ìˆœ ì œë„ˆë ˆì´í„°
import re
import random
import math
import os
from .quiz_parser import DrillSession
from .answer_key import MC_ANSWERS as QUIZ_ANSWERS  # ì •ë‹µí‘œëŠ” answer_key.pyì—ì„œ import

# ê³ ì • íŒŒì¼ ê²½ë¡œ
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
DATA_DIR = os.path.join(BASE_DIR, "data")
MODE2_FILE = os.path.join(DATA_DIR, "4_Data_Structure_Code.txt")
MODE4_FILE = os.path.join(DATA_DIR, "5_Computational_Math_Theory.txt")


def get_fixed_file_for_mode(mode: int) -> str | None:
    """ëª¨ë“œë³„ ê³ ì • íŒŒì¼ ê²½ë¡œ ë°˜í™˜"""
    if mode == 2:
        if os.path.exists(MODE2_FILE):
            return MODE2_FILE
    elif mode == 4:
        if os.path.exists(MODE4_FILE):
            return MODE4_FILE
    return None


def build_local_session(content: str, mode: int, difficulty: int = 2) -> DrillSession:
    """
    ================================================================================
    LLM ì—†ì´ ë¡œì»¬ì—ì„œ í•™ìŠµ ì„¸ì…˜ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
    ================================================================================
    
    ì´ í•¨ìˆ˜ëŠ” ì›¹ UIì—ì„œ "ì„¸ì…˜ ìƒì„±" ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ í˜¸ì¶œë©ë‹ˆë‹¤.
    ì…ë ¥ëœ í…ìŠ¤íŠ¸ íŒŒì¼ì„ ë¶„ì„í•˜ì—¬ í•™ìŠµìš© ë¬¸ì œ ì„¸ì…˜ì„ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        content: ì…ë ¥ í…ìŠ¤íŠ¸ (íŒŒì¼ ë‚´ìš©)
        mode: í•™ìŠµ ëª¨ë“œ ë²ˆí˜¸
        difficulty: ë‚œì´ë„ (1=Easy, 2=Normal, 3=Hard, 4=Extreme)
    
    Returns:
        DrillSession: ìƒì„±ëœ í•™ìŠµ ì„¸ì…˜
    """
    import traceback
    from pathlib import Path
    
    # ë¡œê¹…ìš© (ì„œë²„ì—ì„œ log_error í•¨ìˆ˜ ì‚¬ìš©)
    log_file = Path(__file__).parent.parent / "logs" / "server_error.log"
    def log(msg):
        try:
            from datetime import datetime
            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            with open(log_file, "a", encoding="utf-8") as f:
                f.write(f"[{timestamp}] [local_generator] {msg}\n")
                f.flush()
        except:
            pass
    
    try:
        log(f"build_local_session ì‹œì‘: mode={mode}, diff={difficulty}, content_len={len(content)}")
        
        # 1. ëª¨ë“œë³„ ê³ ì • íŒŒì¼ í™•ì¸ (ë‚œì´ë„ ë¬´ì‹œ)
        fixed_file = get_fixed_file_for_mode(mode)
        if fixed_file and os.path.exists(fixed_file):
            log(f"ê³ ì • íŒŒì¼ ì‚¬ìš©: {fixed_file}")
            with open(fixed_file, 'r', encoding='utf-8') as f:
                content = f.read()
        
        # 2. ì´ë¯¸ ê°ê´€ì‹ ë¬¸ì œ í˜•ì‹ì¸ì§€ ê°ì§€
        if is_existing_quiz(content):
            log(f"ê¸°ì¡´ ë¬¸ì œ í˜•ì‹ ê°ì§€ë¨ â†’ parse_existing_quiz í˜¸ì¶œ")
            result = parse_existing_quiz(content, mode)
            log(f"parse_existing_quiz ì™„ë£Œ: {type(result)}")
            return result
        
        # 3. ëª¨ë“œë³„ ì²˜ë¦¬
        log(f"ëª¨ë“œ {mode}ì— ë§ëŠ” ë³€í™˜ í•¨ìˆ˜ í˜¸ì¶œ")
        
        if mode in (1, 2):
            # ë‚œì´ë„ë³„ ê³ ì • ë¹ˆì¹¸ ê°œìˆ˜ ì„¤ì •
            # 1(Easy): 30ê°œ, 2(Normal): 50ê°œ, 3(Hard): 60ê°œ, 4(Extreme): 80ê°œ
            fixed_counts = {1: 30, 2: 50, 3: 60, 4: 80}
            target = fixed_counts.get(difficulty, 50)
            log(f"ë¹ˆì¹¸ ìƒì„± ëª©í‘œ: {target}ê°œ (ë‚œì´ë„ {difficulty})")
            log(f"ë‚œì´ë„ë³„ ë¹ˆì¹¸ ê°œìˆ˜: ì‰¬ì›€=30, ë³´í†µ=50, ì–´ë ¤ì›€=60, ê·¹í•œ=80")
            
            question, answer_key = make_blanks_with_context(content, target)
            if mode == 2:
                answer_key["_type"] = "fill_in_blank_inline"
            return DrillSession(mode, question, content, answer_key)
            
        if mode == 3:
            question, answer_key = make_implementation_challenge(content)
            return DrillSession(mode, question, content, answer_key)

            
        if mode == 4:
            question, answer_key = make_multiple_choice(content)
            return DrillSession(mode, question, content, answer_key)
            
        if mode == 5:
            question, answer_key = make_definition_quiz(content)
            return DrillSession(mode, question, content, answer_key)
            
        if mode == 7:
            question, answer_key = make_vocabulary_cards(content)
            return DrillSession(mode, question, content, answer_key)
        
        # ê¸°ë³¸ ë°˜í™˜
        log(f"ì•Œ ìˆ˜ ì—†ëŠ” ëª¨ë“œ {mode}, ê¸°ë³¸ ì„¸ì…˜ ë°˜í™˜")
        return DrillSession(mode, content, content, {})
        
    except Exception as e:
        log(f"build_local_session ì˜¤ë¥˜: {e}\n{traceback.format_exc()}")
        # ì—ëŸ¬ ë°œìƒ ì‹œì—ë„ ë¹ˆ ì„¸ì…˜ ë°˜í™˜ (ì„œë²„ í¬ë˜ì‹œ ë°©ì§€)
        return DrillSession(mode, "ì„¸ì…˜ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ", str(e), {"_error": str(e)})


def is_existing_quiz(content: str) -> bool:
    """ì´ë¯¸ ê°ê´€ì‹ ë¬¸ì œ í˜•ì‹ì¸ì§€ ê°ì§€"""
    quiz_patterns = [
        r'[â‘ â‘¡â‘¢â‘£â‘¤]',
        r'^\s*\d+\.\s+.+',
        r'ì‹¤í–‰\s*ê²°ê³¼',
        r'ë¹ˆì¹¸ì—\s*ë“¤ì–´ê°ˆ',
    ]
    
    matches = 0
    for pattern in quiz_patterns:
        if re.search(pattern, content, re.MULTILINE):
            matches += 1
    
    return matches >= 2


def parse_existing_quiz(content: str, mode: int) -> DrillSession:
    """
    ì´ë¯¸ í˜•ì‹í™”ëœ ë¬¸ì œ íŒŒì¼ íŒŒì‹±
    - ì •ë‹µ ìë™ ë§¤ì¹­ ê¸°ëŠ¥ ì¶”ê°€
    """
    questions = []
    lines = content.split('\n')
    
    i = 0
    seq_num = 0
    current_chapter = 0
    
    while i < len(lines):
        line = lines[i].strip()
        
        # ì±•í„° ê°ì§€
        chapter_match = re.match(r'\[Chapter\s*(\d+)\.', line)
        if chapter_match:
            current_chapter = int(chapter_match.group(1))
            i += 1
            continue
        
        # ìƒˆ ë¬¸ì œ ì‹œì‘ ê°ì§€
        q_match = re.match(r'^(\d+)\.\s*(.+)', line)
        if q_match:
            original_num = q_match.group(1)
            q_text = q_match.group(2).strip()
            code_lines = []
            options = []
            q_type = "unknown"
            
            # ë¬¸ì œ ìœ í˜• ê°ì§€
            if 'ì…ë ¥í•˜ì‹œì˜¤' in q_text or 'ì ìœ¼ì‹œì˜¤' in q_text or 'ì‘ì„±í•˜ì‹œì˜¤' in q_text:
                q_type = "short_answer"
            elif 'ë¹ˆì¹¸' in q_text or 'ë°‘ì¤„' in q_text:
                q_type = "fill_blank"
            else:
                q_type = "multiple_choice"
            
            i += 1
            
            while i < len(lines):
                curr_line = lines[i]
                stripped = curr_line.strip()
                
                if re.match(r'^\d+\.\s+.+', stripped):
                    break
                if stripped.startswith('[Chapter') or stripped.startswith('[chapter'):
                    break
                
                # ì„ ì§€ ê°ì§€
                opt_match = re.match(r'^[â‘ â‘¡â‘¢â‘£â‘¤]\s*(.+)', stripped)
                if opt_match:
                    symbol = stripped[0]
                    opt_num = {'â‘ ': 1, 'â‘¡': 2, 'â‘¢': 3, 'â‘£': 4, 'â‘¤': 5}.get(symbol, 0)
                    opt_text = opt_match.group(1).strip()
                    options.append({
                        'num': opt_num,
                        'text': opt_text
                    })
                    q_type = "multiple_choice"
                    i += 1
                    continue
                
                if stripped.startswith('[') and stripped.endswith(']'):
                    i += 1
                    continue
                
                # ì½”ë“œ ë¼ì¸
                if stripped and not stripped.startswith('#') and (
                    curr_line.startswith('   ') or 
                    curr_line.startswith('\t') or
                    '=' in stripped or
                    stripped.startswith('print') or
                    stripped.startswith('def ') or
                    stripped.startswith('class ') or
                    stripped.startswith('for ') or
                    stripped.startswith('if ') or
                    stripped.startswith('while ') or
                    stripped.startswith('import ') or
                    stripped.startswith('from ') or
                    stripped.startswith('return ') or
                    re.match(r'^[a-zA-Z_][a-zA-Z0-9_]*\s*[=\[\(]', stripped)
                ):
                    code_lines.append(stripped)
                    i += 1
                    continue
                
                i += 1
            
            # ì •ë‹µ ì°¾ê¸°
            answer_key_id = f"{current_chapter}_{original_num}"
            correct_answer = QUIZ_ANSWERS.get(answer_key_id, None)
            
            seq_num += 1
            questions.append({
                'id': seq_num,
                'original_num': original_num,
                'chapter': current_chapter,
                'text': q_text,
                'code': '\n'.join(code_lines) if code_lines else '',
                'options': options,
                'type': q_type,
                'correct': correct_answer  # ì •ë‹µ ì¶”ê°€!
            })
        else:
            i += 1
    
    # answer_key êµ¬ì„±
    mc_count = len([q for q in questions if q['type'] == 'multiple_choice' and q['options']])
    sa_count = len([q for q in questions if q['type'] == 'short_answer' or not q['options']])
    fb_count = len([q for q in questions if q['type'] == 'fill_blank'])
    answered_count = len([q for q in questions if q['correct'] is not None])
    
    answer_key = {
        "_type": "parsed_quiz",
        "_questions": questions,
        "_total": len(questions),
        "_has_answers": answered_count > 0
    }
    
    for q in questions:
        if q['correct'] is not None:
            answer_key[str(q['id'])] = str(q['correct'])
        else:
            answer_key[str(q['id'])] = ""
    
    question_text = f"ì´ {len(questions)}ê°œ ë¬¸ì œ íŒŒì‹±ë¨"
    
    answer_text = f"""ğŸ“ ì´ {len(questions)}ê°œì˜ ë¬¸ì œê°€ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.

ğŸ“Š ë¬¸ì œ ìœ í˜•:
- ê°ê´€ì‹: {mc_count}ê°œ
- ë‹¨ë‹µí˜•/ë¹ˆì¹¸: {sa_count + fb_count}ê°œ

âœ… ì •ë‹µì´ ìˆëŠ” ë¬¸ì œ: {answered_count}ê°œ
(ìë™ ì±„ì  ê°€ëŠ¥!)

ì„ ì§€ë¥¼ í´ë¦­í•˜ë©´ ì¦‰ì‹œ ì±„ì ë©ë‹ˆë‹¤."""
    
    return DrillSession(mode, question_text, answer_text, answer_key)


def is_valid_answer(ans: str) -> bool:
    """ë¹ˆì¹¸ ì •ë‹µìœ¼ë¡œ ì í•©í•œì§€ ê²€ì¦"""
    if not ans or len(ans) <= 1:
        return False
    cleaned = ans.rstrip(")],;").strip()
    if not cleaned:
        return False
    special_only = set("()[]{}:,;'\"` ")
    if all(c in special_only for c in ans):
        return False
    if re.match(r'^[\'\"]\s*[\'\"]?\)?$', ans):
        return False
    if not re.search(r'[a-zA-Z0-9_]', ans):
        return False
    return True


def clean_answer(ans: str) -> str:
    """ì •ë‹µì—ì„œ ë¶ˆí•„ìš”í•œ í›„í–‰ ê´„í˜¸/ì‰¼í‘œ/ì½œë¡  ì œê±°"""
    cleaned = ans.rstrip()
    while cleaned.endswith(')') or cleaned.endswith(',') or cleaned.endswith(';') or cleaned.endswith(':'):
        if cleaned.endswith(')'):
            open_count = cleaned.count('(')
            close_count = cleaned.count(')')
            if close_count > open_count:
                cleaned = cleaned[:-1].rstrip()
            else:
                break
        else:
            cleaned = cleaned[:-1].rstrip()
    return cleaned



def build_inline_blank_code(code: str, blanks: list) -> str:
    """
    Render inline __[N]__ markers using recorded positions, with fallbacks if text search fails.
    blanks: [{"line_num": 4, "answer": "None", "col_offset": 10}, ...]
    """
    lines = code.split("\n")
    blanks_by_line: dict[int, list[dict]] = {}
    for blank in blanks:
        line_num = int(blank.get("line_num", 0))
        blanks_by_line.setdefault(line_num, []).append(blank)

    result_lines = []
    for i, line in enumerate(lines):
        line_num = i + 1
        line_blanks = blanks_by_line.get(line_num)
        if not line_blanks:
            result_lines.append(line)
            continue

        modified_line = line
        sorted_blanks = sorted(
            line_blanks,
            key=lambda b: -(b.get("col_offset", -1) if b.get("col_offset", -1) != -1 else b.get("blank_num", 0))
        )

        for blank in sorted_blanks:
            answer = str(blank.get("answer", "")).strip()
            col_offset = blank.get("col_offset", -1)
            marker = f"__[{blank.get('blank_num')}]__"
            insert_at = -1

            if col_offset is not None and col_offset >= 0 and col_offset + len(answer) <= len(modified_line):
                segment = modified_line[col_offset:col_offset + len(answer)]
                if segment == answer:
                    insert_at = col_offset

            if insert_at == -1 and answer:
                insert_at = modified_line.find(answer)

            if insert_at != -1:
                modified_line = modified_line[:insert_at] + marker + modified_line[insert_at + len(answer):]
            else:
                modified_line = f"{modified_line.rstrip()} {marker}".strip()

        result_lines.append(modified_line)

    return "\n".join(result_lines)


def make_blanks_with_context(code: str, target_count: int):
    """
    AST-based blank generation with CONCEPT-UNIT extraction.
    
    Key Principles:
    1. Extract CONCEPT UNITS, not individual tokens
       - Full conditions: "current.link is not None" as one blank
       - Full pointer assignments: "current.link = node" as one blank
    2. Weighted Priority:
       - Pointer/Structure manipulation (weight 3): head=, current.link=, pre.link=
       - Control conditions (weight 3): if/while conditions
       - Boundary checks (weight 2): index < 0, head is None
       - Return values (weight 1): return result
    3. Distribute evenly across FUNCTIONS
    4. Maintain minimum LINE DISTANCE between blanks
    5. Avoid duplicates of same concept pattern
    """
    import ast
    
    # ========== CONFIGURATION ==========
    MIN_LINE_DISTANCE = 2  # Minimum lines between blanks
    
    # Weights for scoring
    WEIGHT_POINTER = 3      # head, current, pre, node, .link assignments
    WEIGHT_CONDITION = 3    # if/while/for conditions
    WEIGHT_BOUNDARY = 2     # index < 0, head is None boundary checks
    WEIGHT_RETURN = 1       # return statements
    WEIGHT_EXCLUDED = 0     # print, menu, file I/O
    
    # Function importance weights for distribution
    FUNCTION_WEIGHTS = {
        'appendNode': 3, 'insertNode': 3, 'insertAt': 3, 'deleteNode': 3,
        'searchNode': 2, 'printNodes': 1, 'get_list_data': 1,
        'Node': 1, '__init__': 1,
        'saveToFile': 0.5, 'loadFromFile': 0.5, 'clearList': 0.5,
        '__main__': 0.3, 'main': 0.3,
    }
    DEFAULT_FUNC_WEIGHT = 1.0
    
    # Pointer-related identifiers to detect
    POINTER_IDENTIFIERS = {'head', 'current', 'pre', 'node', 'newNode', 'temp'}
    
    # Excluded patterns (don't create blanks for these)
    EXCLUDED_LINE_PATTERNS = [
        r'^\s*print\s*\(["\']',      # Print with string literal
        r'^\s*#',                     # Comments
        r'^\s*"""',                   # Docstrings
        r"^\s*'''",                   # Docstrings
        r'^\s*def\s+\w+\s*\(',       # Function definitions (name only)
        r'^\s*class\s+\w+',          # Class definitions
    ]
    
    lines = code.splitlines()
    candidates = []
    
    # ========== HELPER FUNCTIONS ==========
    
    def get_source_segment(code_lines: list, start_line: int, start_col: int, 
                           end_line: int, end_col: int) -> str:
        """Extract source code segment from line/column positions."""
        if start_line == end_line:
            return code_lines[start_line - 1][start_col:end_col]
        result = [code_lines[start_line - 1][start_col:]]
        for line_idx in range(start_line, end_line - 1):
            result.append(code_lines[line_idx])
        result.append(code_lines[end_line - 1][:end_col])
        return '\n'.join(result)
    
    def get_text_from_node(node, code_lines: list) -> str:
        """Get source text for an AST node."""
        if not hasattr(node, 'lineno') or not hasattr(node, 'end_lineno'):
            return ""
        try:
            return get_source_segment(
                code_lines, node.lineno, node.col_offset,
                node.end_lineno, node.end_col_offset
            )
        except (IndexError, AttributeError):
            return ""
    
    def is_pointer_related(node) -> bool:
        """Check if node involves pointer/structure manipulation."""
        text = get_text_from_node(node, lines)
        # Check for pointer identifiers or .link attribute
        if '.link' in text:
            return True
        for ident in POINTER_IDENTIFIERS:
            if re.search(rf'\b{ident}\b', text):
                return True
        return False
    
    def is_excluded_line(line: str) -> bool:
        """Check if line should be excluded from blank generation."""
        for pattern in EXCLUDED_LINE_PATTERNS:
            if re.match(pattern, line):
                return True
        return False
    
    def detect_current_function(node, func_map: dict) -> str:
        """Find which function contains this node based on line number."""
        line = getattr(node, 'lineno', 0)
        containing_func = '__global__'
        for func_name, (start, end) in func_map.items():
            if start <= line <= end:
                containing_func = func_name
        return containing_func
    
    # ========== AST PARSING ==========
    
    try:
        tree = ast.parse(code)
    except SyntaxError:
        # Fallback to simple token-based extraction if AST fails
        return _fallback_token_blanks(code, target_count)
    
    # Build function map: function_name -> (start_line, end_line)
    func_map = {}
    for node in ast.walk(tree):
        if isinstance(node, ast.FunctionDef):
            end_line = node.end_lineno if hasattr(node, 'end_lineno') else node.lineno + 20
            func_map[node.name] = (node.lineno, end_line)
        elif isinstance(node, ast.ClassDef):
            for item in node.body:
                if isinstance(item, ast.FunctionDef):
                    end_line = item.end_lineno if hasattr(item, 'end_lineno') else item.lineno + 10
                    func_map[f"{node.name}.{item.name}"] = (item.lineno, end_line)
    
    # ========== CANDIDATE EXTRACTION ==========
    
    for node in ast.walk(tree):
        line_num = getattr(node, 'lineno', 0)
        if line_num == 0 or line_num > len(lines):
            continue
        
        line_text = lines[line_num - 1]
        if is_excluded_line(line_text):
            continue
        
        func_name = detect_current_function(node, func_map)
        
        # --- 1. If/While/For CONDITIONS (Priority: WEIGHT_CONDITION or WEIGHT_BOUNDARY) ---
        if isinstance(node, (ast.If, ast.While)):
            condition_text = get_text_from_node(node.test, lines)
            if condition_text and len(condition_text) > 2:
                # Determine if this is a boundary check
                is_boundary = any(kw in condition_text for kw in 
                    ['is None', '< 0', '> len', '>= len', 'is not None', '== 0', 'index'])
                score = WEIGHT_BOUNDARY if is_boundary else WEIGHT_CONDITION
                
                # Extra boost for pointer-related conditions
                if is_pointer_related(node.test):
                    score = WEIGHT_CONDITION
                
                candidates.append({
                    'type': 'condition',
                    'text': condition_text,
                    'line_num': line_num,
                    'col_offset': node.test.col_offset,
                    'score': score,
                    'function': func_name,
                    'full_line': line_text,
                })
        
        # --- 2. For loop iterables ---
        elif isinstance(node, ast.For):
            iter_text = get_text_from_node(node.iter, lines)
            if iter_text and len(iter_text) > 2:
                candidates.append({
                    'type': 'for_iter',
                    'text': iter_text,
                    'line_num': line_num,
                    'col_offset': node.iter.col_offset,
                    'score': WEIGHT_CONDITION,
                    'function': func_name,
                    'full_line': line_text,
                })
        
        # --- 3. POINTER/STRUCTURE ASSIGNMENTS (Priority: WEIGHT_POINTER) ---
        elif isinstance(node, ast.Assign):
            # Check if this is a pointer-related assignment
            assign_text = get_text_from_node(node, lines)
            
            # Look for patterns like: head = node, current.link = node, etc.
            target_text = ""
            for target in node.targets:
                target_text = get_text_from_node(target, lines)
                break
            
            value_text = get_text_from_node(node.value, lines)
            
            is_pointer_assign = False
            # Check if LHS has pointer identifiers or .link
            if target_text:
                if '.link' in target_text:
                    is_pointer_assign = True
                for ident in POINTER_IDENTIFIERS:
                    if target_text == ident or target_text.startswith(f"{ident}."):
                        is_pointer_assign = True
                        break
            
            if is_pointer_assign and assign_text and len(assign_text) > 3:
                candidates.append({
                    'type': 'pointer_assign',
                    'text': assign_text.strip(),
                    'line_num': line_num,
                    'col_offset': node.col_offset,
                    'score': WEIGHT_POINTER,
                    'function': func_name,
                    'full_line': line_text,
                })
        
        # --- 4. RETURN STATEMENTS (Priority: WEIGHT_RETURN) ---
        elif isinstance(node, ast.Return):
            if node.value:
                return_val = get_text_from_node(node.value, lines)
                if return_val and len(return_val) > 1:
                    candidates.append({
                        'type': 'return',
                        'text': return_val,
                        'line_num': line_num,
                        'col_offset': node.value.col_offset,
                        'score': WEIGHT_RETURN,
                        'function': func_name,
                        'full_line': line_text,
                    })
    
    # ========== DISTRIBUTION ALGORITHM ==========
    
    # Group candidates by function
    by_function = {}
    for cand in candidates:
        func = cand['function']
        by_function.setdefault(func, []).append(cand)
    
    # Sort candidates within each function by score (descending)
    for func in by_function:
        by_function[func].sort(key=lambda c: -c['score'])
    
    # Calculate target allocation per function
    total_weight = sum(FUNCTION_WEIGHTS.get(f.split('.')[-1], DEFAULT_FUNC_WEIGHT) 
                       for f in by_function.keys())
    if total_weight == 0:
        total_weight = len(by_function)
    
    allocations = {}
    for func in by_function:
        func_base = func.split('.')[-1]  # Handle Class.method names
        weight = FUNCTION_WEIGHTS.get(func_base, DEFAULT_FUNC_WEIGHT)
        alloc = max(1, round(target_count * weight / total_weight))
        allocations[func] = alloc
    
    # Select candidates with line distance constraint
    selected = []
    used_lines = set()
    used_patterns = set()  # Track concept patterns to avoid duplicates
    
    for func_name in sorted(by_function.keys(), 
                           key=lambda f: -FUNCTION_WEIGHTS.get(f.split('.')[-1], DEFAULT_FUNC_WEIGHT)):
        func_candidates = by_function[func_name]
        func_quota = allocations.get(func_name, 1)
        func_selected = 0
        
        for cand in func_candidates:
            if func_selected >= func_quota:
                break
            
            line = cand['line_num']
            
            # Check minimum line distance
            if any(abs(line - used) < MIN_LINE_DISTANCE for used in used_lines):
                continue
            
            # Check for duplicate pattern (same text in same function)
            pattern_key = (func_name, cand['text'][:20])
            if pattern_key in used_patterns:
                continue
            
            selected.append(cand)
            used_lines.add(line)
            used_patterns.add(pattern_key)
            func_selected += 1
    
    # Fill remaining quota from high-score leftovers
    remaining = target_count - len(selected)
    if remaining > 0:
        leftover = [c for c in candidates if c not in selected]
        leftover.sort(key=lambda c: -c['score'])
        
        for cand in leftover:
            if len(selected) >= target_count:
                break
            
            line = cand['line_num']
            if any(abs(line - used) < MIN_LINE_DISTANCE for used in used_lines):
                continue
            
            selected.append(cand)
            used_lines.add(line)
    
    # If still not enough, add more with relaxed constraints
    if len(selected) < target_count:
        leftover = [c for c in candidates if c not in selected]
        leftover.sort(key=lambda c: (-c['score'], c['line_num']))
        for cand in leftover:
            if len(selected) >= target_count:
                break
            selected.append(cand)
    
    selected = selected[:target_count]
    
    # ========== BUILD OUTPUT ==========
    
    # Sort by line/column and assign blank numbers
    selected.sort(key=lambda b: (b['line_num'], b.get('col_offset', 0)))
    for idx, blank in enumerate(selected, 1):
        blank['blank_num'] = idx
        blank['answer'] = blank['text']  # For compatibility with build_inline_blank_code
    
    answer_key = {
        "_type": "fill_in_blank_inline",
        "_blanks": selected,
        "_original_code": code,
    }
    for blank in selected:
        answer_key[str(blank["blank_num"])] = blank["text"]
    
    question_text = build_inline_blank_code(code, selected)
    return question_text, answer_key


def _fallback_token_blanks(code: str, target_count: int):
    """
    Fallback to simple token-based blank generation if AST parsing fails.
    """
    lines = code.splitlines()
    token_re = re.compile(r"[A-Za-z_][A-Za-z0-9_]*|\b\d+\b")
    
    EXCLUDED_KEYWORDS = {
        'print', 'def', 'class', 'import', 'from', 'as', 'pass',
        'True', 'False', 'None', 'self', 'cls',
        '__init__', '__main__', '__name__',
    }
    
    candidates = []
    for i, line in enumerate(lines):
        stripped = line.strip()
        if not stripped or stripped.startswith('#'):
            continue
        
        for match in token_re.finditer(line):
            answer = match.group().strip()
            if answer in EXCLUDED_KEYWORDS or len(answer) <= 1:
                continue
            
            candidates.append({
                "line_num": i + 1,
                "answer": answer,
                "text": answer,
                "full_line": line.rstrip("\n"),
                "col_offset": match.start(),
            })
    
    random.shuffle(candidates)
    blanks = candidates[:target_count]
    blanks.sort(key=lambda b: (b["line_num"], b.get("col_offset", 0)))
    
    for idx, blank in enumerate(blanks, 1):
        blank["blank_num"] = idx
    
    answer_key = {
        "_type": "fill_in_blank_inline",
        "_blanks": blanks,
        "_original_code": code,
    }
    for blank in blanks:
        answer_key[str(blank["blank_num"])] = blank["answer"]
    
    question_text = build_inline_blank_code(code, blanks)
    return question_text, answer_key

def make_implementation_challenge(code: str):
    """
    ì½”ë“œ ì „ì²´ë¥¼ ì„¹ì…˜ë³„ë¡œ ë¶„ë¦¬í•˜ì—¬ ë°±ì§€ë³µìŠµ ì±Œë¦°ì§€ ìƒì„±
    - í•¨ìˆ˜ (def)
    - í´ë˜ìŠ¤ (class) 
    - ì „ì—­ ë³€ìˆ˜ ì„ ì–¸
    - if __name__ == "__main__": ë¸”ë¡
    - ì£¼ì„ìœ¼ë¡œ êµ¬ë¶„ëœ ì„¹ì…˜
    """
    lines = code.splitlines()
    challenges = []
    
    # 1ë‹¨ê³„: ì½”ë“œë¥¼ ì„¹ì…˜ìœ¼ë¡œ ë¶„ë¦¬
    sections = []
    current_section = {"type": "code", "header": "", "lines": [], "start_line": 1}
    
    i = 0
    while i < len(lines):
        line = lines[i]
        stripped = line.strip()
        
        # ì£¼ì„ ì„¹ì…˜ í—¤ë” ê°ì§€ (## ... ##)
        if stripped.startswith("##") and stripped.endswith("##"):
            if current_section["lines"]:
                sections.append(current_section)
            current_section = {"type": "section_header", "header": stripped, "lines": [], "start_line": i + 1}
            i += 1
            continue
        
        # if __name__ == "__main__": ë¸”ë¡ ê°ì§€
        if stripped.startswith('if __name__') and '__main__' in stripped:
            if current_section["lines"]:
                sections.append(current_section)
            current_section = {"type": "main_block", "header": line, "lines": [], "start_line": i + 1}
            i += 1
            # ì´í›„ ëª¨ë“  ì¤„ì„ ë©”ì¸ ë¸”ë¡ìœ¼ë¡œ ì²˜ë¦¬
            while i < len(lines):
                current_section["lines"].append(lines[i])
                i += 1
            sections.append(current_section)
            current_section = {"type": "code", "header": "", "lines": [], "start_line": i + 1}
            continue
        
        # í´ë˜ìŠ¤ ì •ì˜ ê°ì§€
        if stripped.startswith("class "):
            if current_section["lines"]:
                sections.append(current_section)
            current_section = {"type": "class", "header": line, "lines": [], "start_line": i + 1}
            indent_match = re.match(r"(\s*)", line)
            class_indent = indent_match.group(1) + "    "
            i += 1
            # í´ë˜ìŠ¤ ë³¸ì²´ ìˆ˜ì§‘
            while i < len(lines):
                curr_line = lines[i]
                curr_stripped = curr_line.strip()
                if curr_stripped == "" or curr_line.startswith(class_indent) or curr_stripped.startswith(("#", '"""', "'''")):
                    current_section["lines"].append(curr_line)
                    i += 1
                else:
                    break
            sections.append(current_section)
            current_section = {"type": "code", "header": "", "lines": [], "start_line": i + 1}
            continue
        
        # í•¨ìˆ˜ ì •ì˜ ê°ì§€
        if stripped.startswith("def "):
            if current_section["lines"]:
                sections.append(current_section)
            current_section = {"type": "function", "header": line, "lines": [], "start_line": i + 1}
            indent_match = re.match(r"(\s*)", line)
            func_indent = indent_match.group(1) + "    "
            i += 1
            # í•¨ìˆ˜ ë³¸ì²´ ìˆ˜ì§‘
            while i < len(lines):
                curr_line = lines[i]
                curr_stripped = curr_line.strip()
                if curr_stripped == "" or curr_line.startswith(func_indent) or curr_stripped.startswith(("#", '"""', "'''")):
                    current_section["lines"].append(curr_line)
                    i += 1
                else:
                    break
            sections.append(current_section)
            current_section = {"type": "code", "header": "", "lines": [], "start_line": i + 1}
            continue
        
        # ì „ì—­ ë³€ìˆ˜ ë˜ëŠ” ì¼ë°˜ ì½”ë“œ
        current_section["lines"].append(line)
        i += 1
    
    # ë§ˆì§€ë§‰ ì„¹ì…˜ ì¶”ê°€
    if current_section["lines"]:
        sections.append(current_section)
    
    # 2ë‹¨ê³„: ì„¹ì…˜ì„ ì±Œë¦°ì§€ë¡œ ë³€í™˜
    for section in sections:
        body_text = "\n".join(section["lines"]).strip()
        
        # ë¹ˆ ì„¹ì…˜ ì œì™¸
        if not body_text:
            continue
        
        # ì„¹ì…˜ í—¤ë”ë§Œ ìˆëŠ” ê²½ìš° ì œì™¸
        if section["type"] == "section_header":
            continue
        
        # ë¹ˆ ì¤„ë§Œ ìˆëŠ” ê²½ìš° ì œì™¸
        if not body_text.replace("\n", "").strip():
            continue
        
        # í—¤ë” ê²°ì •
        if section["type"] == "function":
            header = section["header"]
        elif section["type"] == "class":
            header = section["header"]
        elif section["type"] == "main_block":
            header = section["header"]
        elif section["type"] == "code":
            # ì „ì—­ ë³€ìˆ˜ë‚˜ ì¼ë°˜ ì½”ë“œ ë¸”ë¡
            first_line = body_text.split("\n")[0].strip()
            if "=" in first_line:
                header = "# ì „ì—­ ë³€ìˆ˜ ì„ ì–¸"
            else:
                header = "# ì½”ë“œ ë¸”ë¡"
        else:
            header = "# ì½”ë“œ"
        
        challenges.append({
            "signature": header,
            "body": body_text,
            "line_num": section["start_line"],
            "type": section["type"]
        })
    
    answer_key = {
        "_type": "implementation_challenge",
        "_challenges": challenges,
        "_original_code": code
    }
    for idx, ch in enumerate(challenges, 1):
        answer_key[str(idx)] = ch["body"]
    
    question_text = "\n".join([f"[ì±Œë¦°ì§€ {i+1}] {ch['signature'].strip()}" for i, ch in enumerate(challenges)])
    return question_text, answer_key


def make_multiple_choice(code: str, num_questions: int = 10):
    """ì½”ë“œì—ì„œ ê°ê´€ì‹ ë¬¸ì œ ìƒì„±"""
    lines = code.splitlines()
    candidates = []
    
    for i, line in enumerate(lines):
        stripped = line.strip()
        if stripped.startswith(("def ", "class ", "import ", "from ", "#", '"""', "'''")):
            continue
        if not stripped:
            continue
        
        assign_match = re.search(r"=\s*([^#\n=]+)$", line)
        if assign_match:
            raw_ans = assign_match.group(1).strip()
            ans = clean_answer(raw_ans)
            if is_valid_answer(ans):
                context_start = max(0, i - 3)
                context_end = min(len(lines), i + 4)
                context = "\n".join(lines[context_start:context_end])
                question_line = line.replace(ans, "_____", 1)
                context_with_blank = context.replace(line, question_line, 1)
                
                candidates.append({
                    "context": context_with_blank,
                    "answer": ans,
                    "line_num": i + 1,
                    "full_line": line
                })
        
        return_match = re.search(r"return\s+([^#\n]+)$", line)
        if return_match:
            raw_ans = return_match.group(1).strip()
            ans = clean_answer(raw_ans)
            if is_valid_answer(ans):
                context_start = max(0, i - 3)
                context_end = min(len(lines), i + 4)
                context = "\n".join(lines[context_start:context_end])
                question_line = line.replace(ans, "_____", 1)
                context_with_blank = context.replace(line, question_line, 1)
                
                candidates.append({
                    "context": context_with_blank,
                    "answer": ans,
                    "line_num": i + 1,
                    "full_line": line
                })
    
    random.shuffle(candidates)
    selected = candidates[:num_questions]
    all_answers = list(set(c["answer"] for c in candidates))
    
    questions = []
    answer_key = {}
    
    for idx, item in enumerate(selected, 1):
        correct = item["answer"]
        wrong_pool = [a for a in all_answers if a != correct]
        if len(wrong_pool) < 3:
            wrong_pool.extend(["None", "True", "False", "self", "0", "1", "[]", "{}"])
            wrong_pool = list(set(wrong_pool) - {correct})
        
        wrong_choices = random.sample(wrong_pool, min(3, len(wrong_pool)))
        choices = [correct] + wrong_choices
        random.shuffle(choices)
        correct_index = choices.index(correct) + 1
        
        questions.append({
            "num": idx,
            "text": "ë‹¤ìŒ ì½”ë“œì˜ ë¹ˆì¹¸ì— ë“¤ì–´ê°ˆ ì•Œë§ì€ ê²ƒì€?",
            "code": item["context"],
            "options": [{"num": j+1, "text": c} for j, c in enumerate(choices)],
            "correct": correct_index
        })
        answer_key[str(idx)] = str(correct_index)
    
    full_question = f"ì´ {len(questions)}ê°œ ë¬¸ì œ ìƒì„±ë¨"
    
    answer_key["_type"] = "multiple_choice"
    answer_key["_questions"] = questions
    
    return full_question, answer_key


def make_definition_quiz(content: str):
    """
    OOP ì •ì˜ í€´ì¦ˆ ìƒì„± (Mode 5)
    
    ì§€ì› í˜•ì‹:
    1. ì‰¼í‘œ êµ¬ë¶„: ìš©ì–´,ì •ì˜
    2. ì¤„ë°”ê¿ˆ êµ¬ë¶„: ìš©ì–´(ì˜ë¬¸) / ì •ì˜ (êµëŒ€ë¡œ)
    
    ì˜ˆì‹œ (ì‰¼í‘œ êµ¬ë¶„):
    ë©”ì„œë“œ ì˜¤ë²„ë¡œë”© (Method Overloading),ê°™ì€ ì´ë¦„ì˜ ë©”ì„œë“œë¥¼ ë§¤ê°œë³€ìˆ˜ë§Œ ë‹¤ë¥´ê²Œ ì—¬ëŸ¬ ê°œ ì •ì˜í•˜ëŠ” ê²ƒ
    
    ì˜ˆì‹œ (ì¤„ë°”ê¿ˆ êµ¬ë¶„):
    ë©”ì„œë“œ ì˜¤ë²„ë¡œë”©(Method Overloading)
    ê°™ì€ ì´ë¦„ì˜ ë©”ì„œë“œë¥¼ ë§¤ê°œë³€ìˆ˜ë§Œ ë‹¤ë¥´ê²Œ ì—¬ëŸ¬ ê°œ ì •ì˜í•˜ëŠ” ê²ƒ
    """
    lines = content.strip().split('\n')
    definitions = []
    
    for line in lines:
        line = line.strip()
        if not line:
            continue
        
        # í˜•ì‹ 1: ì‰¼í‘œë¡œ êµ¬ë¶„ (ìš©ì–´,ì •ì˜)
        if ',' in line:
            parts = line.split(',', 1)  # ì²« ë²ˆì§¸ ì‰¼í‘œì—ì„œë§Œ ë¶„ë¦¬
            if len(parts) == 2:
                term = parts[0].strip()
                definition = parts[1].strip()
                if term and definition:
                    definitions.append({
                        'term': term,
                        'definition': definition
                    })
                    continue
    
    # í˜•ì‹ 1ì—ì„œ ëª» ì°¾ì•˜ìœ¼ë©´ í˜•ì‹ 2 ì‹œë„ (ì¤„ë°”ê¿ˆ êµ¬ë¶„)
    if not definitions:
        i = 0
        while i < len(lines):
            term_line = lines[i].strip()
            if not term_line:
                i += 1
                continue
            
            if i + 1 < len(lines):
                def_line = lines[i + 1].strip()
                if def_line and not re.match(r'^[ê°€-í£a-zA-Z]+\s*\(', def_line):
                    definitions.append({
                        'term': term_line,
                        'definition': def_line
                    })
                    i += 2
                    continue
            i += 1
    
    answer_key = {
        "_type": "definition_quiz",
        "_definitions": definitions,
        "_total": len(definitions)
    }
    
    for idx, item in enumerate(definitions, 1):
        answer_key[str(idx)] = item['definition']
    
    question_text = f"ì´ {len(definitions)}ê°œ ì •ì˜ ë¬¸ì œ ìƒì„±ë¨"
    return question_text, answer_key


def make_vocabulary_cards(content: str):
    """
    ì˜ë‹¨ì–´ í”Œë˜ì‹œì¹´ë“œ ìƒì„± (Mode 7)
    
    ì§€ì› í˜•ì‹:
    1. ì‰¼í‘œ êµ¬ë¶„: ì˜ë‹¨ì–´, ëœ»1, ëœ»2, ...
    2. êµ¬ë¶„ì êµ¬ë¶„: ì˜ë‹¨ì–´ -> ëœ» ë˜ëŠ” ì˜ë‹¨ì–´: ëœ»
    3. ì˜ì–´ë§Œ: AI ìƒì„± í•„ìš”
    
    ì˜ˆì‹œ:
    inheritance, ìƒì†, ìœ ì‚°
    interface -> ì ‘ì 
    abstract: ì¶”ìƒì ì¸
    """
    lines = content.strip().split('\n')
    words = []
    
    for line in lines:
        line = line.strip()
        if not line:
            continue
        
        # í˜•ì‹ 1: ì‰¼í‘œë¡œ êµ¬ë¶„ (ì˜ë‹¨ì–´, ëœ»1, ëœ»2, ...)
        if ',' in line:
            parts = line.split(',')
            if len(parts) >= 2:
                eng = parts[0].strip()
                # ì²« ë²ˆì§¸ ëœ»ë§Œ ì‚¬ìš©í•˜ê±°ë‚˜, ëª¨ë“  ëœ» í•©ì¹˜ê¸°
                kor = ', '.join(p.strip() for p in parts[1:] if p.strip())
                if eng and kor and re.match(r'^[a-zA-Z\s]+', eng):
                    words.append({
                        'english': eng,
                        'korean': kor,
                        'needs_ai': False
                    })
                    continue
        
        # í˜•ì‹ 2: êµ¬ë¶„ìë¡œ êµ¬ë¶„ (-> : = ë“±)
        if re.search(r'[-:=â†’]', line):
            parts = re.split(r'\s*[-:=â†’]\s*', line, 1)
            if len(parts) >= 2:
                eng = parts[0].strip()
                kor = parts[1].strip()
                if eng and kor and re.match(r'^[a-zA-Z]+', eng):
                    if not is_transliteration(eng, kor):
                        words.append({
                            'english': eng,
                            'korean': kor,
                            'needs_ai': False
                        })
                        continue
        
        # í˜•ì‹ 3: ì˜ì–´ë§Œ ìˆëŠ” ê²½ìš° - AI ìƒì„± í•„ìš”
        if re.match(r'^[a-zA-Z]+$', line):
            words.append({
                'english': line,
                'korean': '',
                'needs_ai': True
            })
    
    answer_key = {
        "_type": "vocabulary_cards",
        "_words": words,
        "_total": len(words),
        "_needs_ai_generation": any(w['needs_ai'] for w in words)
    }
    
    for idx, item in enumerate(words, 1):
        answer_key[str(idx)] = item['korean'] if item['korean'] else "[AI ìƒì„± í•„ìš”]"
    
    question_text = f"ì´ {len(words)}ê°œ ì˜ë‹¨ì–´ ì¹´ë“œ ìƒì„±ë¨"
    return question_text, answer_key


def is_transliteration(english: str, korean: str) -> bool:
    """
    ë‹¨ìˆœ ìŒì—­ì¸ì§€ í™•ì¸
    ì˜ˆ: code -> ì½”ë“œ, interface -> ì¸í„°í˜ì´ìŠ¤
    """
    transliteration_pairs = {
        'code': 'ì½”ë“œ',
        'interface': 'ì¸í„°í˜ì´ìŠ¤',
        'class': 'í´ë˜ìŠ¤',
        'object': 'ì˜¤ë¸Œì íŠ¸',
        'method': 'ë©”ì„œë“œ',
        'function': 'í‘ì…˜',
        'module': 'ëª¨ë“ˆ',
        'package': 'íŒ¨í‚¤ì§€',
        'library': 'ë¼ì´ë¸ŒëŸ¬ë¦¬',
        'framework': 'í”„ë ˆì„ì›Œí¬',
        'server': 'ì„œë²„',
        'client': 'í´ë¼ì´ì–¸íŠ¸',
        'database': 'ë°ì´í„°ë² ì´ìŠ¤',
        'process': 'í”„ë¡œì„¸ìŠ¤',
        'thread': 'ìŠ¤ë ˆë“œ',
        'memory': 'ë©”ëª¨ë¦¬',
        'file': 'íŒŒì¼',
        'system': 'ì‹œìŠ¤í…œ',
        'program': 'í”„ë¡œê·¸ë¨',
        'data': 'ë°ì´í„°',
        'type': 'íƒ€ì…',
        'list': 'ë¦¬ìŠ¤íŠ¸',
        'array': 'ì–´ë ˆì´',
        'string': 'ìŠ¤íŠ¸ë§',
        'integer': 'ì¸í‹°ì €',
        'boolean': 'ë¶ˆë¦¬ì–¸',
        'null': 'ë„',
        'error': 'ì—ëŸ¬',
        'debug': 'ë””ë²„ê·¸',
        'test': 'í…ŒìŠ¤íŠ¸',
        'api': 'ì—ì´í”¼ì•„ì´',
        'url': 'ìœ ì•Œì—˜',
    }
    
    eng_lower = english.lower()
    kor_clean = korean.strip()
    
    # ì§ì ‘ ë§¤í•‘ í™•ì¸
    if eng_lower in transliteration_pairs:
        if transliteration_pairs[eng_lower] == kor_clean:
            return True
    
    # ìŒì—­ íŒ¨í„´ í™•ì¸ (í•œê¸€ì´ 5ì ì´ë‚´ì´ê³  ì˜ì–´ì™€ ë¹„ìŠ·í•œ ê¸¸ì´)
    if len(kor_clean) <= 5 and len(eng_lower) <= len(kor_clean) * 2:
        # ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±: í•œê¸€ì´ ë„ˆë¬´ ì§§ìœ¼ë©´ ìŒì—­ì¼ ê°€ëŠ¥ì„± ë†’ìŒ
        if len(kor_clean) <= 3:
            return True
    
    return False
